
Pipeline stages
---------------

5 stage RISC pipeline:

  1       2        3          	           4              5 
Fetch - Decode - Execute 	 - Memory read	    - Writeback / memory write

Hazards
-------

To compute hazards, memory address written to, and register written to, must be tracked.
If an instruction accesses the saved addresses or registers, the pipeline will stall.
A nop will be inserted into the pipeline (bubble) at the decode stage and the PC will not advance.
Hence the same instruction will be decoded until the hazard clears.

If the instruction to be fetched is at an address that is marked as "hot", the PC will not advance and a nopwill be inserted at the fetch stage, which will be decoded as nop, causing a pipeline bubble until the memory address is removed from the "hot" list.

In order to prevent pipeline stall with instruction sequences such as :-

	cmp r0, 0
	jump nz 1
	...
1:

The flags (Z, C) are updated in the execute stage. Similarly the imm instruction must update the
internal IMM 14-bit register in the execute stage, so it can be accessed on the following execute 
cycle to prevent pipeline stalls.

Branch prediction
-----------------

A simple table of the last four branches and their targets is used to prevent pipeline stalls in tight loops. If the branch prediction fails, the entire pipeline will be flush and reloaded from the new PC.

Cache
-----


Caching is used to speed up memory accesses in stages 1 and 4.

For performance, cache is a single level, and implemented in block ram. There are separate instruction and data caches, to boot performance.

For writes to memory, write must be initiated in stage 4 and completed in stage 5, if the cache hits. If the cache misses, the whole pipeline must stall until the entire matching cacheline can be filled from memory.   

To allow multi-cycle reads and writes, the cache is dual port. The pipeline stages access the ports as follows:-

	Port used in each pipeline stage for data memory access
Stage	4     5
	-------
t = 0	0--\  -
t = 1	1-\ \-0
t = 2	0  \--1

i.e. the port accessed in stage 4 is used by the same instruction in stage 5 etc. If the cache misses in stage 5, the instruction in stage 4 must remain in stage 4 until the cache line accessed in stage 5 is fetched from memory. Similar for a read.



Clockrate
---------

Aim is for 50+ D-Mips from 50 - 72 MHz clock. (?)


Dual issue
----------

To boost performance, there are two instruction pipelines, which can be built with configuration parameter ENABLE_DUAL_ISSUE set to non-zero. For this case PC and PC + 1 are fetched from the same instruction cache each cycle, and there are separate data caches. In this way, instructions can be sequenced which access different parts of memory in each pipeline. Instructions that also do not access the same address or register or access flags (such as conditional calls and jumps, or arithmetic / logical instructions using carry) can be executed in parallel. 

Hazards
-------
 

